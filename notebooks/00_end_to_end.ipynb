{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "00_end_to_end.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hackathon 2025 — Pipeline de ponta a ponta\n",
        "\n",
        "Este notebook reproduz o pipeline completo de geração das previsões e montagem do arquivo de submissão **JAN/2023**.\n",
        "\n",
        "**Saídas esperadas**:\n",
        "- `reports/submission_final_JAN2023.csv` — CSV final com separador `;` (UTF‑8)\n",
        "- `reports/submission_final_JAN2023.csv.gz` — versão compactada\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Configuração\n",
        "Ajuste os parâmetros abaixo se necessário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os, sys, subprocess, textwrap\n",
        "\n",
        "# URL do repositório (ajuste caso use um fork)\n",
        "REPO_URL = \"https://github.com/Guedes1981/hackathon-forecast-2025.git\"\n",
        "WORKDIR  = Path(\"/content/drive/MyDrive/hackathon-forecast-2025\") if Path(\"/content\").exists() else Path.cwd()/\"hackathon-forecast-2025\"\n",
        "\n",
        "print(\"WORKDIR:\", WORKDIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Obter o código (clone ou atualizar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import subprocess, os\n",
        "if not WORKDIR.exists():\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, str(WORKDIR)], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"-C\", str(WORKDIR), \"pull\"], check=True)\n",
        "print(\"OK - código disponível em:\", WORKDIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Instalação de dependências\n",
        "Tenta instalar a partir do `requirements.txt` do projeto. Se não houver, usa um conjunto padrão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "req_proj = WORKDIR/\"requirements.txt\"\n",
        "if req_proj.exists():\n",
        "    print(\"Instalando dependências do projeto…\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(req_proj)], check=True)\n",
        "else:\n",
        "    # Fallback: usa requirements.txt incluído neste pacote\n",
        "    from pathlib import Path\n",
        "    fallback_reqs = Path(\"requirements.txt\") if Path(\"requirements.txt\").exists() else Path(\"/mnt/data/requirements.txt\")\n",
        "    print(\"Instalando dependências padrão… (fallback)\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(fallback_reqs)], check=True)\n",
        "print(\"OK - dependências instaladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) (Opcional) Rodar validação Prophet (val4)\n",
        "Gera `data/processed/prophet_topN_val4_preds.parquet` e métricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cmd = [\n",
        "    sys.executable, \"-u\", str(WORKDIR/\"src\"/\"train_prophet_topn.py\"),\n",
        "    \"--top_n\", \"200\",\n",
        "    \"--changepoint_prior_scale\", \"0.8\",\n",
        "    \"--val_split\", \"val4\",\n",
        "    \"--out_parquet\", str(WORKDIR/\"data/processed/prophet_topN_val4_preds.parquet\"),\n",
        "]\n",
        "print(\"Executando:\", \" \".join(cmd))\n",
        "try:\n",
        "    subprocess.run(cmd, check=True)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"[Aviso] Validação falhou (seguindo adiante):\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Rodar produção (Jan/2023) — Prophet\n",
        "Usa a flag `--predict_jan2023` implementada no script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "out_jan = WORKDIR/\"data/processed/prophet_topN_jan2023_preds.parquet\"\n",
        "cmd = [\n",
        "    sys.executable, \"-u\", str(WORKDIR/\"src\"/\"train_prophet_topn.py\"),\n",
        "    \"--top_n\", \"200\", \"--changepoint_prior_scale\", \"0.8\",\n",
        "    \"--predict_jan2023\",\n",
        "    \"--out_parquet\", str(out_jan),\n",
        "]\n",
        "print(\"Executando:\", \" \".join(cmd))\n",
        "subprocess.run(cmd, check=True)\n",
        "print(\"OK - Prophet Jan/2023:\", out_jan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Ensemble\n",
        "Gera `data/processed/forecast_ensemble_jan2023.parquet` (usar caminhos padrão do script)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cmd = [sys.executable, \"-u\", str(WORKDIR/\"src\"/\"forecast_ensemble.py\")]\n",
        "print(\"Executando:\", \" \".join(cmd))\n",
        "subprocess.run(cmd, check=True)\n",
        "print(\"OK - ensemble gerado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Montar CSV final (`;`, UTF‑8)\n",
        "Cria `reports/submission_final_JAN2023.csv` no formato exigido: `semana;pdv;produto;quantidade`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "ens_pq = WORKDIR/\"data/processed/forecast_ensemble_jan2023.parquet\"\n",
        "out_csv = WORKDIR/\"reports/submission_final_JAN2023.csv\"\n",
        "out_gz  = WORKDIR/\"reports/submission_final_JAN2023.csv.gz\"\n",
        "\n",
        "df = pd.read_parquet(ens_pq)\n",
        "# Normalização de nomes\n",
        "ren = {}\n",
        "for c in df.columns:\n",
        "    lc = c.lower()\n",
        "    if lc in (\"sku\",\"sku_id\",\"produto_id\",\"product\",\"product_id\"): ren[c] = \"produto\"\n",
        "    elif lc in (\"pdv\",\"pdv_id\",\"store\",\"store_id\"): ren[c] = \"pdv\"\n",
        "    elif lc in (\"date\",\"dt\",\"ds\",\"semana\"): ren[c] = \"ds\"\n",
        "    elif lc in (\"pred\",\"prediction\",\"forecast\",\"y_pred\",\"yhat_prophet\",\"yhat_baseline\",\"ens_pred\",\"yhat_ensemble\",\"yhat\"): ren[c] = \"yhat\"\n",
        "df = df.rename(columns=ren)\n",
        "\n",
        "# Extrai chaves de \"id\" se necessário\n",
        "if \"id\" in df.columns and (\"pdv\" not in df.columns or \"produto\" not in df.columns):\n",
        "    ids = df[\"id\"].astype(str).str.split(\"|\", n=1, expand=True)\n",
        "    if ids.shape[1] == 2:\n",
        "        df[\"pdv\"], df[\"produto\"] = ids[0], ids[1]\n",
        "\n",
        "# Tipos e datas\n",
        "for k in (\"pdv\",\"produto\"): df[k] = df[k].astype(str)\n",
        "df[\"ds\"] = pd.to_datetime(df.get(\"ds\"), errors=\"coerce\")\n",
        "try: df[\"ds\"] = df[\"ds\"].dt.tz_localize(None)\n",
        "except Exception: pass\n",
        "\n",
        "# MA(4) caso não haja yhat\n",
        "if \"yhat\" not in df.columns:\n",
        "    keys = [\"produto\",\"pdv\"] if {\"produto\",\"pdv\"}.issubset(df.columns) else [\"sku_id\",\"pdv_id\"]\n",
        "    aux = df.rename(columns={\"sku_id\":\"produto\",\"pdv_id\":\"pdv\"})\n",
        "    aux = aux.sort_values(keys + ([\"ds\"] if \"ds\" in aux.columns else []))\n",
        "    aux[\"ma4\"] = aux.groupby(keys, sort=False)[\"quantidade\" if \"quantidade\" in aux.columns else \"y\" if \"y\" in aux.columns else \"yhat\"].rolling(4, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "    df[\"yhat\"] = aux[\"ma4\"].values\n",
        "\n",
        "# Filtra semanas de JAN/2023 (dias 02,09,16,23) e mapeia para 1..4\n",
        "wmap = {2:1, 9:2, 16:3, 23:4}\n",
        "mask_jan = (df[\"ds\"].dt.month == 1) & (df[\"ds\"].dt.year == 2023) & (df[\"ds\"].dt.day.isin(wmap))\n",
        "dfj = df.loc[mask_jan, [\"ds\",\"pdv\",\"produto\",\"yhat\"]].copy()\n",
        "dfj[\"semana\"] = dfj[\"ds\"].dt.day.map(wmap)\n",
        "dfj[\"quantidade\"] = (dfj[\"yhat\"].clip(lower=0).round().astype(int))\n",
        "dfj = dfj[[\"semana\",\"pdv\",\"produto\",\"quantidade\"]]\n",
        "dfj = dfj.sort_values([\"semana\",\"pdv\",\"produto\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Linhas:\", len(dfj))\n",
        "print(\"Semanas:\", dfj[\"semana\"].min(), \"->\", dfj[\"semana\"].max())\n",
        "print(\"Nulos por coluna:\", dfj.isna().sum().to_dict())\n",
        "\n",
        "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
        "dfj.to_csv(out_csv, sep=';', index=False, encoding='utf-8')\n",
        "dfj.to_csv(out_gz, sep=';', index=False, encoding='utf-8', compression='gzip')\n",
        "print(\"OK - salvo:\", out_csv)\n",
        "print(\"OK - salvo (gz):\", out_gz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Verificações finais (hashes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import hashlib\n",
        "def file_hash(path, algo=\"md5\"):\n",
        "    h = hashlib.new(algo)\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "csv_path = WORKDIR/\"reports/submission_final_JAN2023.csv\"\n",
        "gz_path  = WORKDIR/\"reports/submission_final_JAN2023.csv.gz\"\n",
        "print(\"MD5 csv   :\", file_hash(csv_path, \"md5\"))\n",
        "print(\"MD5 gz    :\", file_hash(gz_path, \"md5\"))\n",
        "print(\"SHA256 csv:\", file_hash(csv_path, \"sha256\"))\n",
        "print(\"SHA256 gz :\", file_hash(gz_path, \"sha256\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) (Opcional) Commit/Push/Tag do artefato final\n",
        "Se desejar versionar os artefatos gerados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import subprocess\n",
        "subprocess.run([\"git\", \"-C\", str(WORKDIR), \"add\", \"README.md\", \"reports/submission_final_JAN2023.csv\", \"reports/submission_final_JAN2023.csv.gz\"], check=False)\n",
        "subprocess.run([\"git\", \"-C\", str(WORKDIR), \"commit\", \"-m\", \"feat: artefato final de submissao (JAN/2023)\"], check=False)\n",
        "subprocess.run([\"git\", \"-C\", str(WORKDIR), \"push\"], check=False)\n",
        "subprocess.run([\"git\", \"-C\", str(WORKDIR), \"tag\", \"-f\", \"v-final-jan2023\"], check=False)\n",
        "subprocess.run([\"git\", \"-C\", str(WORKDIR), \"push\", \"-f\", \"origin\", \"v-final-jan2023\"], check=False)\n",
        "print(\"OK - versionamento final (se repositório estiver autenticado)\")"
      ]
    }
  ]
}